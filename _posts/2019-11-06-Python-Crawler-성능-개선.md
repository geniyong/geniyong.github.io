---
tags : Python Django
title : Python - Crawler 성능 개선
---

## 개요
&nbsp;적게는 수 만개에서 많게는 수 백만 개의 웹 사이트에 각각 접속하여 데이터를 가져오는 크롤러를 개발하면서 `크롤러`의 본질적인 문제들을 만나고 해결하는 과정을 반복했다. `크롤러`의 본질적인 문제라 하면 안티봇에 관한 정책으로 인한 문제(크롤링을 금지하는 정책) 또는 이를 위한 솔루션(캡챠) 등으로 인한 문제이다. 하지만 이러한 문제는 창과 방패의 싸움과 같이 소모적인 성격이 크다. 문제가 발생할 때 어떻게 하면 금지 정책을 우회할 수 있을까 또는 보안 솔루션을 우회할 수 있을까 다방면적으로 분석하여 해결방법을 찾아나가야한다. 결국 이런 해결방법들은 사실상 해킹으로 봐도 무방하다.              
&nbsp;그러나 본 포스팅에서는 크롤러의 이런 소모적 성격의 문제들이 아닌, 보다 본질적인 Python 기반의 크롤링 속도에 관한 문제를 파헤치고자 한다. 단순하게 네이버의 메인페이지 html 을 크롤링 하여 데이터를 취하는 정도의 예시로는 크롤링 속도에 관한 문제에 다가가기 힘들 것이다. 왜냐하면 네이버의 메인페이지 html 을 가져오는 행위(I/O) 즉, HTTP Request 행위는 단 한번 발생하였고 (Input) 이에 대한 Response (Output) 를 받으면 그 즉시 CPU 를 이용하여 데이터를 취할 수 있기 때문이다. 하지만 네이버의 메인페이지 html 내에서 얻을 수 있는 모든 URL 을 다시 요청하고 받아온 html 내에서 얻을 수 있는 URL 을 다시 요청하는... 반복적인 행위가 필요하다면 크롤링 속도에 관해 문제를 제기할 수 있을 것이다. 그렇다면 먼저 크롤링의 속도가 어떤 요인들에 의해 작용되는지를 알아야지 결과적으로 속도 개선의 방향성을 잡을 것이다.         


## 크롤링 - 컴퓨터 처리 관점
&nbsp;크롤링 작업은 `I/O Bound` 에 해당하는 **HTTP Request/Response 행위 + 필요한 데이터는 데이터베이스로 저장하는 행위**와 `CPU Bound` 에 해당하는 **html 데이터의 파싱행위** 크게 둘로 나뉜다.             
`I/O Bound` : I/O 란 입출력, Input Output 을 의미하며 I/O Bound 에는 Disk I/O, Network I/O 등이 포함된다.        
`CPU Bound` : CPU Bound 는 CPU의 속도에 직접적인 연관이 있는 행위들이다. 이를테면 연산 행위가 이에 해당한다.         
따라서, 크롤링 작업은 사실상 웹 사이트를 요청하여 가져오는 행위 즉, Network I/O 가 가장 핵심이며 가져온 HTML 데이터를 연산/가공 하여 필요한 정보만을 추출하여 데이터베이스로 저장하는 작업이다. 네이버 HTML 을 가져와서 실시간 검색어의 ELEMENT 선택자를 통해 파싱하여 실시간 검색어를 얻어 온 뒤 검색어 목록을 나의 데이터베이스에 저장하는 것처럼 말이다.      

## 크롤링 속도 문제
&nbsp;한번의 요청과 그와 수반되는 데이터 처리작업만 놓고 보면 문제시 될 만큼의 속도가 느리지도 않거니와 설령 속도가 느리다 할지라도 성능 개선의 여지가 보이지 않는다. 왜냐하면 어찌 됐던 데이터를 네트워크를 통해 가져와야하는데 이 속도가 느리다고 한다면 요청 측과 응답 측의 근본적인 네트워크 (망구성) 구조적 개선을 해야하기 때문이다. 그러나 위에서 말한 예시와 같이 수만, 수십만개의 사이트를 연속적으로 크롤링 하고자 할 때는 속도 이슈가 더욱 크게 다가 올 것이며 개선의 여지가 있기 때문에 방치하지 않고 어떻게 개선할 지 연구해볼만한 가치가 있다.


`Python Interpreter` 에 해당하는 `CPython` 의 `GIL` 로 인한
